{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cbb10a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2568ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "\n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = 0.0\n",
    "    self._backward = lambda: None\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Value(data={self.data})\"\n",
    "\n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "\n",
    "  def __pow__(self, other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "    out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "    def _backward():\n",
    "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "\n",
    "  def __rmul__(self, other): \n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other): \n",
    "    return self * other**-1\n",
    "\n",
    "  def __neg__(self): \n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): \n",
    "    return self + (-other)\n",
    "\n",
    "  def __radd__(self, other): \n",
    "    return self + other\n",
    "\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "\n",
    "  def exp(self):\n",
    "    x = self.data\n",
    "    out = Value(math.exp(x), (self, ), 'exp')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad \n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "  def backward(self):\n",
    "\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "\n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "      node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3086600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = [xi if isinstance(xi, Value) else Value(xi) for xi in x]\n",
    "\n",
    "        act = sum((wi * xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts):  \n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "367be26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.5699685524526016)\n",
      "Value(data=0.14811880062450147)\n",
      "Value(data=0.5289931002653167)\n",
      "Value(data=0.42139440515858645)\n"
     ]
    }
   ],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n",
    "n = MLP(3, [4, 5, 2, 1])\n",
    "for x in xs:\n",
    "    y_pred = n(x)\n",
    "    print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62e1cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(n.parameters())\n",
    "a\n",
    "n = MLP(3, [4, 5, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "42ca069e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.018867732977056288\n",
      "1 0.01843671885637243\n",
      "2 0.018024288805281067\n",
      "3 0.017629284299847746\n",
      "4 0.017250640277716077\n",
      "5 0.016887375958309633\n",
      "6 0.016538586719216212\n",
      "7 0.016203436890146868\n",
      "8 0.015881153346209733\n",
      "9 0.015571019799294795\n",
      "10 0.015272371700709563\n",
      "11 0.014984591680308097\n",
      "12 0.014707105457595633\n",
      "13 0.014439378168986447\n",
      "14 0.01418091106279086\n",
      "15 0.013931238519824932\n",
      "16 0.013689925362944357\n",
      "17 0.013456564423440844\n",
      "18 0.013230774336234648\n",
      "19 0.013012197539235736\n",
      "20 0.012800498455223519\n",
      "21 0.012595361837172752\n",
      "22 0.01239649126019069\n",
      "23 0.01220360774517958\n",
      "24 0.012016448501035892\n",
      "25 0.011834765773682157\n",
      "26 0.011658325791526439\n",
      "27 0.01148690779808325\n",
      "28 0.011320303163491597\n",
      "29 0.011158314567546831\n",
      "30 0.011000755247640819\n",
      "31 0.01084744830569015\n",
      "32 0.010698226068741726\n",
      "33 0.010552929498481058\n",
      "34 0.010411407645348637\n",
      "35 0.010273517143393009\n",
      "36 0.01013912174236847\n",
      "37 0.010008091873921526\n",
      "38 0.009880304249012697\n",
      "39 0.009755641483987955\n",
      "40 0.009633991752956697\n",
      "41 0.009515248464347693\n",
      "42 0.009399309959709773\n",
      "43 0.009286079232997688\n",
      "44 0.00917546366874038\n",
      "45 0.00906737479763058\n",
      "46 0.008961728068202349\n",
      "47 0.008858442633377605\n",
      "48 0.008757441150767509\n",
      "49 0.008658649595708369\n"
     ]
    }
   ],
   "source": [
    "for k in range(50):\n",
    "    y_pred = [n(x) for x in xs]\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,y_pred))\n",
    "    for p in n.parameters():\n",
    "        p.grad =0.0\n",
    "    loss.backward()\n",
    "\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05*p.grad\n",
    "    print(k,loss.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "202fedab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.9558038100925752)\n",
      "Value(data=-0.967130930232524)\n",
      "Value(data=-0.9527358312321814)\n",
      "Value(data=0.9426029923508877)\n"
     ]
    }
   ],
   "source": [
    "for x in xs:\n",
    "    y_pred = n(x)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dbab17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0014906258624189127\n",
      "1 0.0014874566106961402\n",
      "2 0.001484300506134243\n",
      "3 0.00148115746785167\n",
      "4 0.0014780274156256322\n",
      "5 0.0014749102698854628\n",
      "6 0.0014718059517060118\n",
      "7 0.00146871438280112\n",
      "8 0.0014656354855172127\n",
      "9 0.0014625691828269209\n",
      "10 0.0014595153983228294\n",
      "11 0.0014564740562112068\n",
      "12 0.0014534450813059787\n",
      "13 0.0014504283990225482\n",
      "14 0.0014474239353719385\n",
      "15 0.0014444316169547502\n",
      "16 0.001441451370955445\n",
      "17 0.0014384831251364385\n",
      "18 0.0014355268078325308\n",
      "19 0.00143258234794516\n",
      "20 0.001429649674936848\n",
      "21 0.0014267287188257614\n",
      "22 0.0014238194101802003\n",
      "23 0.0014209216801132315\n",
      "24 0.001418035460277392\n",
      "25 0.0014151606828594213\n",
      "26 0.0014122972805750726\n",
      "27 0.0014094451866639647\n",
      "28 0.0014066043348845364\n",
      "29 0.0014037746595090164\n",
      "30 0.00140095609531848\n",
      "31 0.0013981485775979227\n",
      "32 0.0013953520421314297\n",
      "33 0.0013925664251974162\n",
      "34 0.0013897916635638326\n",
      "35 0.00138702769448357\n",
      "36 0.001384274455689771\n",
      "37 0.0013815318853912441\n",
      "38 0.0013787999222680404\n",
      "39 0.0013760785054668738\n",
      "40 0.0013733675745967627\n",
      "41 0.0013706670697246363\n",
      "42 0.0013679769313710666\n",
      "43 0.0013652971005059186\n",
      "44 0.0013626275185441956\n",
      "45 0.0013599681273418272\n",
      "46 0.0013573188691915485\n",
      "47 0.0013546796868188417\n",
      "48 0.0013520505233778673\n",
      "49 0.0013494313224474861\n"
     ]
    }
   ],
   "source": [
    "for k in range(50):\n",
    "    y_pred = [n(x) for x in xs]\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,y_pred))\n",
    "    for p in n.parameters():\n",
    "        p.grad =0.0\n",
    "    loss.backward()\n",
    "\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05*p.grad\n",
    "    print(k,loss.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b83ee8",
   "metadata": {},
   "source": [
    "BEFORE:\n",
    "Value(data=0.9558038100925752)\n",
    "Value(data=-0.967130930232524)\n",
    "Value(data=-0.9527358312321814)\n",
    "Value(data=0.9426029923508877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09ea9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.9827963814814136)\n",
      "Value(data=-0.9855447945318717)\n",
      "Value(data=-0.9806587764557552)\n",
      "Value(data=0.9783708149811414)\n"
     ]
    }
   ],
   "source": [
    "for x in xs:\n",
    "    y_pred = n(x)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params, why pow, mul n all,topo in vlaue , \n",
    "#neuron - mlp part and layers , their params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56e185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvLLM (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
